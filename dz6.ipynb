{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25da5d24-eb51-4803-bed4-b1da0ff1c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /wheels/flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl (from -r requirements.txt (line 36))\n",
      "Requirement already satisfied: accelerate==1.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: aiohttp==3.13.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.13.3)\n",
      "Requirement already satisfied: aiosignal==1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: annotated-doc==0.0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.0.4)\n",
      "Requirement already satisfied: anyio==4.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.12.1)\n",
      "Requirement already satisfied: argon2-cffi==25.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (25.1.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==25.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: arrow==1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: asttokens==3.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.0.1)\n",
      "Requirement already satisfied: async-lru==2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.1.0)\n",
      "Requirement already satisfied: async-timeout==5.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (5.0.1)\n",
      "Requirement already satisfied: attrs==25.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (25.4.0)\n",
      "Requirement already satisfied: babel==2.18.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (2.18.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.14.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (4.14.3)\n",
      "Requirement already satisfied: bitsandbytes==0.48.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.48.1)\n",
      "Requirement already satisfied: bleach==6.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (6.3.0)\n",
      "Requirement already satisfied: certifi==2026.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2026.1.4)\n",
      "Requirement already satisfied: cffi==2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer==3.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (3.4.4)\n",
      "Requirement already satisfied: click==8.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (8.3.1)\n",
      "Requirement already satisfied: comm==0.2.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.2.3)\n",
      "Requirement already satisfied: contourpy==1.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (1.3.2)\n",
      "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (0.12.1)\n",
      "Requirement already satisfied: datasets==4.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (4.5.0)\n",
      "Requirement already satisfied: debugpy==1.8.20 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (1.8.20)\n",
      "Requirement already satisfied: decorator==5.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (5.2.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.7.1)\n",
      "Requirement already satisfied: dill==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (0.4.0)\n",
      "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (5.6.3)\n",
      "Requirement already satisfied: einops==0.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.8.2)\n",
      "Requirement already satisfied: exceptiongroup==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (1.3.1)\n",
      "Requirement already satisfied: executing==2.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (2.2.1)\n",
      "Requirement already satisfied: fastjsonschema==2.21.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (2.21.2)\n",
      "Requirement already satisfied: filelock==3.20.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (3.20.0)\n",
      "Requirement already satisfied: fonttools==4.61.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (4.61.1)\n",
      "Requirement already satisfied: fqdn==1.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (1.5.1)\n",
      "Requirement already satisfied: frozenlist==1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (1.8.0)\n",
      "Requirement already satisfied: fsspec==2025.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (2025.10.0)\n",
      "Requirement already satisfied: h11==0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (0.16.0)\n",
      "Requirement already satisfied: hf-xet==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.0.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 43)) (1.0.9)\n",
      "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 44)) (0.28.1)\n",
      "Requirement already satisfied: huggingface_hub==0.36.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 45)) (0.36.2)\n",
      "Requirement already satisfied: idna==3.11 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (3.11)\n",
      "Requirement already satisfied: ipykernel==7.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 47)) (7.2.0)\n",
      "Requirement already satisfied: ipython==8.38.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 48)) (8.38.0)\n",
      "Requirement already satisfied: ipywidgets==8.1.8 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 49)) (8.1.8)\n",
      "Requirement already satisfied: isoduration==20.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (20.11.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 51)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 52)) (3.1.6)\n",
      "Requirement already satisfied: json5==0.13.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 53)) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 54)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.26.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 55)) (4.26.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2025.9.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 56)) (2025.9.1)\n",
      "Requirement already satisfied: jupyter-events==0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 57)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-lsp==2.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 58)) (2.3.0)\n",
      "Requirement already satisfied: jupyter_client==8.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 59)) (8.8.0)\n",
      "Requirement already satisfied: jupyter_core==5.9.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 60)) (5.9.1)\n",
      "Requirement already satisfied: jupyter_server==2.17.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 61)) (2.17.0)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 62)) (0.5.4)\n",
      "Requirement already satisfied: jupyterlab==4.5.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 63)) (4.5.4)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 64)) (0.3.0)\n",
      "Requirement already satisfied: jupyterlab_server==2.28.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 65)) (2.28.0)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.16 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 66)) (3.0.16)\n",
      "Requirement already satisfied: kiwisolver==1.4.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 67)) (1.4.9)\n",
      "Requirement already satisfied: lark==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 68)) (1.3.1)\n",
      "Requirement already satisfied: llama_cpp_python==0.3.16 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 69)) (0.3.16)\n",
      "Requirement already satisfied: markdown-it-py==4.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 70)) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe==2.1.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 71)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib==3.10.8 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 72)) (3.10.8)\n",
      "Requirement already satisfied: matplotlib-inline==0.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 73)) (0.2.1)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 74)) (0.1.2)\n",
      "Requirement already satisfied: mistune==3.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 75)) (3.2.0)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 76)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 77)) (6.7.1)\n",
      "Requirement already satisfied: multiprocess==0.70.18 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 78)) (0.70.18)\n",
      "Requirement already satisfied: nbclient==0.10.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 79)) (0.10.4)\n",
      "Requirement already satisfied: nbconvert==7.17.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 80)) (7.17.0)\n",
      "Requirement already satisfied: nbformat==5.10.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 81)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 82)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 83)) (3.4.2)\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 84)) (0.2.4)\n",
      "Requirement already satisfied: numpy==2.2.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 85)) (2.2.6)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 86)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 87)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 88)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 89)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 90)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 91)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 92)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 93)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 94)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 95)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.9.86 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 96)) (12.9.86)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 97)) (12.1.105)\n",
      "Requirement already satisfied: overrides==7.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 98)) (7.7.0)\n",
      "Requirement already satisfied: packaging==26.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 99)) (26.0)\n",
      "Requirement already satisfied: pandas==2.3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 100)) (2.3.3)\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 101)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 102)) (0.8.6)\n",
      "Requirement already satisfied: peft==0.18.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 103)) (0.18.1)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 104)) (4.9.0)\n",
      "Requirement already satisfied: pillow==12.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 105)) (12.0.0)\n",
      "Requirement already satisfied: platformdirs==4.9.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 106)) (4.9.2)\n",
      "Requirement already satisfied: prometheus_client==0.24.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 107)) (0.24.1)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.52 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 108)) (3.0.52)\n",
      "Requirement already satisfied: propcache==0.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 109)) (0.4.1)\n",
      "Requirement already satisfied: protobuf==6.33.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 110)) (6.33.5)\n",
      "Requirement already satisfied: psutil==7.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 111)) (7.2.2)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 112)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 113)) (0.2.3)\n",
      "Requirement already satisfied: pyarrow==23.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 114)) (23.0.1)\n",
      "Requirement already satisfied: pycparser==3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 115)) (3.0)\n",
      "Requirement already satisfied: Pygments==2.19.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 116)) (2.19.2)\n",
      "Requirement already satisfied: pyparsing==3.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 117)) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 118)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger==4.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 119)) (4.0.0)\n",
      "Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 120)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 121)) (6.0.3)\n",
      "Requirement already satisfied: pyzmq==27.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 122)) (27.1.0)\n",
      "Requirement already satisfied: referencing==0.37.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 123)) (0.37.0)\n",
      "Requirement already satisfied: regex==2026.1.15 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 124)) (2026.1.15)\n",
      "Requirement already satisfied: requests==2.32.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 125)) (2.32.5)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 126)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 127)) (0.1.1)\n",
      "Requirement already satisfied: rfc3987-syntax==1.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 128)) (1.1.0)\n",
      "Requirement already satisfied: rich==14.3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 129)) (14.3.3)\n",
      "Requirement already satisfied: rpds-py==0.30.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 130)) (0.30.0)\n",
      "Requirement already satisfied: safetensors==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 131)) (0.7.0)\n",
      "Requirement already satisfied: Send2Trash==2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 132)) (2.1.0)\n",
      "Requirement already satisfied: sentencepiece==0.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 133)) (0.2.1)\n",
      "Requirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 134)) (1.5.4)\n",
      "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 135)) (1.17.0)\n",
      "Requirement already satisfied: soupsieve==2.8.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 136)) (2.8.3)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 137)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 138)) (1.13.1)\n",
      "Requirement already satisfied: terminado==0.18.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 139)) (0.18.1)\n",
      "Requirement already satisfied: tinycss2==1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 140)) (1.4.0)\n",
      "Requirement already satisfied: tokenizers==0.20.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 141)) (0.20.3)\n",
      "Requirement already satisfied: tomli==2.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 142)) (2.4.0)\n",
      "Requirement already satisfied: torch==2.5.1+cu121 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 143)) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchaudio==2.5.1+cu121 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 144)) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision==0.20.1+cu121 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 145)) (0.20.1+cu121)\n",
      "Requirement already satisfied: tornado==6.5.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 146)) (6.5.4)\n",
      "Requirement already satisfied: tqdm==4.67.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 147)) (4.67.3)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 148)) (5.14.3)\n",
      "Requirement already satisfied: transformers==4.46.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 149)) (4.46.3)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 150)) (3.1.0)\n",
      "Requirement already satisfied: trl==0.12.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 151)) (0.12.2)\n",
      "Requirement already satisfied: typer==0.24.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 152)) (0.24.1)\n",
      "Requirement already satisfied: typer-slim==0.24.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 153)) (0.24.0)\n",
      "Requirement already satisfied: typing_extensions==4.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 154)) (4.15.0)\n",
      "Requirement already satisfied: tzdata==2025.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 155)) (2025.3)\n",
      "Requirement already satisfied: uri-template==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 156)) (1.3.0)\n",
      "Requirement already satisfied: urllib3==2.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 157)) (2.6.3)\n",
      "Requirement already satisfied: wcwidth==0.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 158)) (0.6.0)\n",
      "Requirement already satisfied: webcolors==25.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 159)) (25.10.0)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 160)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 161)) (1.9.0)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.15 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 162)) (4.0.15)\n",
      "Requirement already satisfied: xxhash==3.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 163)) (3.6.0)\n",
      "Requirement already satisfied: yarl==1.22.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 164)) (1.22.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab==4.5.4->-r requirements.txt (line 63)) (82.0.0)\n",
      "flash_attn is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50b9ff9-0127-4e9d-9be0-a7ce72dedc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if \"TRANSFORMERS_CACHE\" in os.environ and \"HF_HOME\" not in os.environ:\n",
    "    os.environ[\"HF_HOME\"] = os.environ[\"TRANSFORMERS_CACHE\"]\n",
    "    del os.environ[\"TRANSFORMERS_CACHE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f16cac-9cd0-4642-9b51-0059b0062411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import peft\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, prepare_model_for_kbit_training\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from transformers import TrainingArguments, BitsAndBytesConfig\n",
    "import transformers\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b76c91-cbb8-4507-9979-8e71aa08aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "        print(f'VRAM allocated {allocated}gb, reserved {reserved}gb')\n",
    "    else:\n",
    "        print('No cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5701bf2-a6c9-412c-8a19-0294ca6ad836",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6fc167-5ee0-46e0-8dcc-a76780b84d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d973ef18ac82489882eb7a3780fa61c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# гарантируем eos_token_id\n",
    "if tokenizer.eos_token_id is None and tokenizer.eos_token is not None:\n",
    "    tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "foundation_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                        quantization_config=bnb_config,\n",
    "                                                        device_map=\"auto\",\n",
    "                                                        attn_implementation=\"flash_attention_2\")\n",
    "foundation_model = prepare_model_for_kbit_training(foundation_model)\n",
    "foundation_model.gradient_checkpointing_enable()\n",
    "foundation_model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5360da5-cc31-418c-8490-593ec792b8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_template exists: True\n",
      "chat_template preview:\n",
      " {%- if messages[0][\"role\"] == \"system\" %}\n",
      "    {%- set system_message = messages[0][\"content\"] %}\n",
      "    {%- set loop_messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set loop_messages = messages %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "{%- set user_messages = loop_messages | selectattr(\"role\", \"equalto\", \"user\") | list %}\n",
      "\n",
      "{#- This block checks for alternating user/assistant messages, skipping tool calling messages #}\n",
      "{%- set ns = namespace() %}\n",
      "{%- set ns.index = 0 %}\n",
      "{%- for message in loop_messages %}\n",
      "    {%- if not (message.role == \"tool\" or message.role == \"tool_results\" or (message.tool_calls is defined and message.tool_calls is not none)) %}\n",
      "        {%- if (message[\"role\"] == \"user\") != (ns.index % 2 == 0) %}\n",
      "            {{- raise_exception(\"After the optional system message, conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
      "        {%- endif %}\n",
      "        {%- set ns.index = ns.index + 1 %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "\n",
      "{{- bos_token }}\n",
      "{%- for message in loop_messages %}\n",
      "    {%- if message[\"role\"] == \"user\" %}\n",
      "        {%- if tools is not none and (message == user_messages[-1]) %}\n",
      "            {{- \"[AVAILABLE_TOOLS] [\" }}\n",
      "            {%- for tool in tools %}\n",
      "                {%- set tool = tool.function %}\n",
      "                {{- '{\"type\": \"function\", \"function\": {' }}\n",
      "                {%- for key, val in tool.items() if key != \"return\" %}\n",
      "                    {%- if val is string %}\n",
      "                        {{- '\"' + key + '\": \"' + val + '\"' }}\n",
      "                    {%- else %}\n",
      "                        {{- '\"' + key + '\": ' + val|tojson }}\n",
      "                    {%- endif %}\n",
      "                    {%- if not loop.last %}\n",
      "                        {{- \", \" }}\n",
      "                    {%- endif %}\n",
      "                {%- endfor %}\n",
      "                {{- \"}}\" }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- else %}\n",
      "                    {{- \"]\" }}\n",
      "                {%- endif %}\n",
      "            {%- endfor %}\n",
      "            {{- \"[/AVAILABLE_TOOLS]\" }}\n",
      "            {%- endif %}\n",
      "        {%- if loop.last and system_message is defined %}\n",
      "            {{- \"[INST] \" + system_message + \"\\n\\n\" + message[\"content\"] + \"[/INST]\" }}\n",
      "        {%- else %}\n",
      "            {{- \"[INST] \" + message[\"content\"] + \"[/INST]\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.tool_calls is defined and message.tool_calls is not none %}\n",
      "        {{- \"[TOOL_CALLS] [\" }}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- set out = tool_call.function|tojson %}\n",
      "            {{- out[:-1] }}\n",
      "            {%- if not tool_call.id is defined or tool_call.id|length != 9 %}\n",
      "                {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
      "            {%- endif %}\n",
      "            {{- ', \"id\": \"' + tool_call.id + '\"}' }}\n",
      "            {%- if not loop.last %}\n",
      "                {{- \", \" }}\n",
      "            {%- else %}\n",
      "                {{- \"]\" + eos_token }}\n",
      "            {%- endif %}\n",
      "        {%- endfor %}\n",
      "    {%- elif message[\"role\"] == \"assistant\" %}\n",
      "        {{- \" \" + message[\"content\"]|trim + eos_token}}\n",
      "    {%- elif message[\"role\"] == \"tool_results\" or message[\"role\"] == \"tool\" %}\n",
      "        {%- if message.content is defined and message.content.content is defined %}\n",
      "            {%- set content = message.content.content %}\n",
      "        {%- else %}\n",
      "            {%- set content = message.content %}\n",
      "        {%- endif %}\n",
      "        {{- '[TOOL_RESULTS] {\"content\": ' + content|string + \", \" }}\n",
      "        {%- if not message.tool_call_id is defined or message.tool_call_id|length != 9 %}\n",
      "            {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
      "        {%- endif %}\n",
      "        {{- '\"call_id\": \"' + message.tool_call_id + '\"}[/TOOL_RESULTS]' }}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Only user and assistant roles are supported, with the exception of an initial optional system message!\") }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"chat_template exists:\", bool(getattr(tokenizer, \"chat_template\", None)))\n",
    "print(\"chat_template preview:\\n\", tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d70bc6f-baa0-496a-aec3-119edac36aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(model, inputs, tokenizer, max_new_tokens=1000):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            repetition_penalty=1.5,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d551f27-70f9-4dd1-8361-6b3a86bccd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bf16 supported: True\n"
     ]
    }
   ],
   "source": [
    "print(\"bf16 supported:\", torch.cuda.is_available() and torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8f7a02-3552-45e9-8dc7-434f024d2a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM allocated 4.355072975158691gb, reserved 4.859375gb\n"
     ]
    }
   ],
   "source": [
    "print_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5fbacf6-8ad2-42b7-89d2-61afa293eed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n"
     ]
    }
   ],
   "source": [
    "input_simple_sentences_text = 'I have high temperature. Which pills should I take? Answer with pills, no additional info. Pills:'\n",
    "input_simple_sentences = tokenizer(input_simple_sentences_text, return_tensors='pt').to(foundation_model.device)\n",
    "foundational_outputs_sentence = get_outputs(foundation_model, input_simple_sentences, tokenizer)\n",
    "output = tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "120617ac-ab96-49b6-a272-a4f4285ece48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have high temperature. Which pills should I take? Answer with pills, no additional info. Pills: Tylenol (Acetaminophen) or Advil/Motrin (Ibuprofen). Both can help reduce fever and relieve pain associated with it. Always consult a doctor for proper diagnosis before self-medicating.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8181a72-3806-4b5b-8895-54ebbd2e1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_sentences_text = 'I have high temperature. Which pills should I take? Answer with json, contining pills. Example [\"carbamazepine\", \"lamotrigine\"]. Your answer in json: '\n",
    "input_json_sentences = tokenizer(input_json_sentences_text, return_tensors='pt').to(foundation_model.device)\n",
    "foundational_outputs_sentence = get_outputs(foundation_model, input_json_sentences, tokenizer)\n",
    "output = tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57abe848-2cf9-4b9d-896e-3d2f4d2bf43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have high temperature. Which pills should I take? Answer with json, contining pills. Example [\"carbamazepine\", \"lamotrigine\"]. Your answer in json:  {\\n\"pills\": [   \"ibuprofen\",    \"acetaminophen\"] }'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615825ce-b228-4f3a-aa5c-5ac69f9fb8fd",
   "metadata": {},
   "source": [
    "# Начинаем готовить LORA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e83f444-2d5a-4bd3-a2c3-a59721641c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'mlabonne/FineTome-100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c58a2a6-6984-4e25-a777-a808f3dcc28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations', 'source', 'score'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(dataset_name)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a02ec10-8802-4001-9335-9700b9128fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_openai_format(sample):\n",
    "    messages=[]\n",
    "\n",
    "    conversations = sample['conversations']\n",
    "\n",
    "    for speech in conversations:\n",
    "        if speech['from'] == 'human':\n",
    "            messages.append({'role': 'user', 'content': speech['value']})\n",
    "        elif speech['from'] == 'gpt':\n",
    "            messages.append({'role': 'assistant', 'content': speech['value']})\n",
    "\n",
    "    return {'openai_dialog': messages}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d65772dc-cd14-464e-8a06-9b36da63e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(convert_to_openai_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45ea3c27-ef28-4c4f-bf60-336f05a34bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations', 'source', 'score', 'openai_dialog'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e449a99-3a31-47c8-8422-dc6cdd8b5a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Print the reverse of a string using a for loop.',\n",
       "  'role': 'user'},\n",
       " {'content': 'Here is an example code using a for loop to print the reverse of a string along with a detailed docstring:\\n\\n```python\\ndef print_reverse_string(string):\\n    \"\"\"\\n    Prints the reverse of a given string using a for loop.\\n\\n    Parameters:\\n    string (str): The string to be reversed and printed.\\n\\n    Returns:\\n    None.\\n    \"\"\"\\n\\n    # Iterate through the characters of the string in reverse order\\n    for i in range(len(string)-1, -1, -1):\\n        print(string[i], end=\\'\\')\\n\\n    # Print a new line after printing the whole reversed string\\n    print()\\n\\n# Example usage\\ninput_string = input(\"Enter a string: \")\\nprint_reverse_string(input_string)\\n```\\n\\nIn this code, the `print_reverse_string` function takes a string as input. It uses a for loop to iterate through the characters of the string in reverse order. The for loop starts from the index of the last character (`len(string)-1`) and goes until the first character (`-1`), with a step of `-1`. In each iteration, the function prints the character using the `print` function and `end=\\'\\'` is used to avoid printing the default newline character after each character. Finally, after printing the whole reversed string, `print()` is called to print a new line.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['openai_dialog'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80c5a94f-3720-4d00-bc6a-362714d1177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_chat(sample):\n",
    "    tokenized = tokenizer.apply_chat_template(sample['openai_dialog'], tokenize=False, add_generation_prompt=False, add_special_tokens=False)\n",
    "    return {'text': tokenized}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2803a3b-03d5-4fa3-b256-acde6a358b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(render_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2463bd00-1e40-468c-ba11-eb6dcbb53463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations', 'source', 'score', 'openai_dialog', 'text'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6da055ec-6671-4f55-b380-b86d60785fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] How do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?[/INST] Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.</s>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66f1f3cb-82a1-412e-9c04-cc697e0fc208",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8, # As bigger the R bigger the parameters to train.\n",
    "    lora_alpha=16, # a scaling factor that adjusts the magnitude of the weight matrix. Usually set to 1\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\", 'gate_proj', 'up_proj', 'down_proj'],\n",
    "    #target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    #modules_to_save=[\"embed_tokens\", \"lm_head\"],\n",
    "    lora_dropout=0.05, # Helps to avoid Overfitting.\n",
    "    #bias=\"lora_only\", # this specifies if the bias parameter should be trained.\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f3468b9-fe6a-48e5-a94d-ec3ccdcb0201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 20,971,520 || all params: 7,268,995,072 || trainable%: 0.2885\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(foundation_model, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a110aac2-e10f-4a95-9622-eb6366542571",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = './'\n",
    "\n",
    "output_directory = os.path.join(working_dir, 'peft_lab_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74763eaa-19b0-4a5d-b2b9-b5fe9c4d2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_ids = tokenizer.encode(\"[/INST]\", add_special_tokens=False)\n",
    "\n",
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_ids,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a89e6f13-b4d3-4f75-9947-5920b19210c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97999 1001 1000\n"
     ]
    }
   ],
   "source": [
    "ds = data[\"train\"]  # исходный Dataset\n",
    "\n",
    "# 1) отделяем test (1%)\n",
    "tmp = ds.train_test_split(test_size=0.01, seed=42, shuffle=True)\n",
    "train_val = tmp[\"train\"]\n",
    "test_dataset = tmp[\"test\"]\n",
    "\n",
    "# 2) отделяем val (1% от исходного => 1% / 99% от оставшегося)\n",
    "val_ratio_of_train_val = 0.01 / 0.99\n",
    "tmp2 = train_val.train_test_split(test_size=val_ratio_of_train_val, seed=42, shuffle=True)\n",
    "train_dataset = tmp2[\"train\"]\n",
    "eval_dataset = tmp2[\"test\"]   # validation\n",
    "\n",
    "print(len(train_dataset), len(eval_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0d9d9a8-d793-4290-8f14-35e1b36b9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(seed=42).select(range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca75d7f1-2062-4708-8176-0ac73b3fdc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'source', 'score', 'openai_dialog', 'text'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc8ab94b-4bb9-42d9-aafe-f6f3d9e08426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'source', 'score', 'openai_dialog', 'text'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = eval_dataset.select(range(250))\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b416c471-14b0-4c74-ba85-513717045ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'source', 'score', 'openai_dialog', 'text'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = test_dataset.select(range(250))\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4132104-435d-4ecb-b2ca-6d7d619bfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir=output_directory,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=2,\n",
    "    bf16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=200,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "626d2793-3af8-43ba-87e4-74d8b532f1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b604785958480abf370c754597a4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c356dd3f95f445e788131c7d7d9a1021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = peft_model,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    args=sft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85354fa4-0600-4dc1-bde3-174a099eb851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/1250 : < :, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/1430 : < :, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1668' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/1668 : < :, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/2000 : < :, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 5:46:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.610600</td>\n",
       "      <td>0.610538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.599811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.597700</td>\n",
       "      <td>0.592914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.654900</td>\n",
       "      <td>0.589346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.585565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.583499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.583700</td>\n",
       "      <td>0.589304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.486600</td>\n",
       "      <td>0.587857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.511200</td>\n",
       "      <td>0.588534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.509700</td>\n",
       "      <td>0.588607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.588059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.587188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.546628126335144, metrics={'train_runtime': 20808.5952, 'train_samples_per_second': 0.481, 'train_steps_per_second': 0.12, 'total_flos': 4.3589237244542976e+17, 'train_loss': 0.546628126335144, 'epoch': 2.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4edca5d2-7ada-490f-80fa-527abd8466cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a96a097dbe45309a078b5068d3ba7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 02:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.619405210018158, 'eval_model_preparation_time': 0.0031, 'eval_runtime': 170.0675, 'eval_samples_per_second': 1.47, 'eval_steps_per_second': 0.188}\n"
     ]
    }
   ],
   "source": [
    "test_trainer = SFTTrainer(\n",
    "    model=trainer.model,\n",
    "    train_dataset=None,\n",
    "    eval_dataset=test_dataset,     # сырой с text\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    args=sft_config,\n",
    ")\n",
    "\n",
    "test_metrics = test_trainer.evaluate()\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80588754-4078-4d0c-a372-492c9c834abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft_lab_outputs/lora_adapter_1/tokenizer_config.json',\n",
       " './peft_lab_outputs/lora_adapter_1/special_tokens_map.json',\n",
       " './peft_lab_outputs/lora_adapter_1/tokenizer.model',\n",
       " './peft_lab_outputs/lora_adapter_1/added_tokens.json',\n",
       " './peft_lab_outputs/lora_adapter_1/tokenizer.json')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_dir = \"./peft_lab_outputs/lora_adapter_1\"\n",
    "\n",
    "peft_model.save_pretrained(adapter_dir)   # сохраняет только веса адаптера + config\n",
    "tokenizer.save_pretrained(adapter_dir)    # важно, если добавляли спец-токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7c4c8d9-c393-4419-99e7-3f2db647ed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32768, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralFlashAttention2(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f748c29-0bc6-4c16-a5be-e2a67fcf2e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bf410aa2ba4af59bf4364ddfca9d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset.save_to_disk('test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b578c826-7dd4-4361-87e3-bfebda0f9a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
